# jemdoc: menu{MENU}{index.html}, nofooter  
==Zhe Huang

~~~
{}{img_left}{pics/zhehuang.jpg}{alt text}{200}{200}
\n
*Zhe Huang*\n\n
[https://thehcalab.web.illinois.edu/ Human-Centered Autonomy Lab]\n
[https://ece.illinois.edu/ Department of Electrical and Computer Engineering], [https://csl.illinois.edu/ Coordinated Science Laboratory]\n
[https://illinois.edu/ University of Illinois Urbana-Champaign]\n\n
Email: zheh4@illinois.edu \n\n
\[[https://scholar.google.com/citations?user=ME-U3iwAAAAJ&hl=en&authuser=1 Google Scholar] |
[https://github.com/tedhuang96 GitHub] | [https://www.linkedin.com/in/zhehuang96/ LinkedIn]\] \n\n
~~~

== About me
I'm a 6th-year Ph.D. candidate advised by Prof. Katherine Driggs-Campbell at University of Illinois Urbana-Champaign. I am also a research scientist at Meta.
I will receive the Ph.D. degree in Electrical and Computer Engineering from University of Illinois Urbana-Champaign in December, 2024.
I received the M.S. degree in Mechanical Engineering from Stanford University in 2019 and 
the B.Eng. degree in Energy and Power Engineering from Xi'an Jiaotong University in 2017.

My research is focused on building *Human-Centered Embodied AI* to enable robots to safely and efficiently interact with humans and the physical world.
A major challenge to achieve this goal is that existing fully autonomous robots do not have sufficient understanding of human behavior,
and act conservatively with humans around to guarantee safety of humans and themselves, which is at the cost of efficiency.
I develop human-centered autonomy frameworks including human prediction and robot planning with human intent and human trajectory
as interface for robots to achieve challenging human-involved open-world tasks.
My works integrate well-established algorithmic primitives and novel machine learning techniques to offer efficiency improvement under safety guarantees.
My works illustrate generality of Human-Centered Embodied AI across various applications including autonomous driving, crowd navigation,
collaborative manufacturing, and collaborative cooking.

My research areas are Robotics, Artificial Intelligence, and Human-Robot Interaction.

My Ph.D. thesis: *Bridging Prediction and Planning for Human-Centered Autonomy*.

== News
- \[2024.10\] I passed my Ph.D. thesis defense.
- \[2024.08\] Our interaction-aware conformal prediction paper [https://www.algorithmic-robotics.org/papers/60_Interaction_aware_Conformal.pdf ICP] is accepted by WAFR 2024.
- \[2024.07\] I am excited to join Meta as a research scientist.
- \[2024.06\] Our paper on [https://arxiv.org/abs/2407.16771 Topology-Guided ORCA] is accepted by [https://unsolvedsocialnav.org/ Unsolved Problems in Social Robot Navigation workshop] in conjunction with RSS 2024.
- \[2024.06\] Our Embodied AI paper [https://arxiv.org/abs/2406.13787 LIT] is selected for *Spotlight Presentation* by [https://computer-vision-in-the-wild.github.io/cvpr-2024/ the 3rd Workshop on Computer Vision in the Wild] at CVPR 2024.
- \[2024.05\] Our Embodied AI paper [https://arxiv.org/abs/2406.13787 LIT] is accepted by both [https://computer-vision-in-the-wild.github.io/cvpr-2024/ the 3rd Workshop on Computer Vision in the Wild] and [https://embodied-ai.org/ the 5th Annual Embodied AI Workshop] at CVPR 2024.
- \[2024.04\] We have released our main implementation for [https://arxiv.org/abs/2309.14595 NIRRT*] on the GitHub repo [https://github.com/tedhuang96/nirrt_star nirrt_star].
- \[2024.02\] We have released our ROS implementation for [https://arxiv.org/abs/2309.14595 NIRRT*] on the GitHub repo [https://github.com/tedhuang96/PNGNav PNGNav].
- \[2024.01\] Our path planning paper [https://arxiv.org/abs/2309.14595 NIRRT*] is accepted by ICRA 2024.
- \[2023.01\] Two papers [https://arxiv.org/abs/2203.09063 Hierarchical Intetion Tracking] and [https://sites.google.com/view/intention-aware-crowdnav/home Intention Aware CrowdNav] are accepted by ICRA 2023.
- \[2022.12\] I finished my internship at Amazon Robotics as an Advanced Robotics Research Co-op.
- \[2022.12\] I am excited to attend [http://www.robot-learning.ml/2022/ the 5th Robot Learning Workshop: Trustworthy Robotics] at NeurIPS 2022 as an invited speaker!
- \[2022.08\] I am excited to join Amazon Robotics as an Advanced Robotics Research Co-op.
- \[2022.08\] I finished my internship at Nuro as a PhD Intern.
- \[2022.08\] We will present our work [https://arxiv.org/abs/2206.01775 Seamless Interaction Design with Coexistence and Cooperation Modes for Robust Human-Robot Collaboration] on CASE 2022 Special Session on Adaptive and Resilient Cyber-Physical Manufacturing Networks.
- \[2022.05\] I am excited to join Nuro as a PhD Intern.
- \[2022.05\] Our work [https://arxiv.org/abs/2205.14340 Insights from an Industrial Collaborative Assembly Project: Lessons in Research and Collaboration] is selected for *Spotlight Presentation* at [https://sites.google.com/view/icra22ws-cor-wotf/accepted-papers?authuser=0 ICRA 2022 Workshop on Collaborative Robots and the Work of the Future].
- \[2022.04\] I am honored to give a talk at Wuhan University titled "Human Behavior Modeling in Autonomous Driving and Collaborative Manufacturing" (自动驾驶与协同制造中的人类行为建模).
- \[2022.02\] Our demo "Human-Robot Collaboration in Industrial Assembly Tasks" is awarded the Best Robotics Demo in [https://studentconference.csl.illinois.edu/ Coordinated Science Laboratory Student Conference].
- \[2022.01\] We will present [https://sites.google.com/view/gumbel-social-transformer GST] on ICRA 2022.
- \[2021.12\] We have released our code for [https://sites.google.com/view/gumbel-social-transformer GST] on the GitHub repo [https://github.com/tedhuang96/gst gst].
- \[2021.12\] One paper [https://sites.google.com/view/gumbel-social-transformer GST] is accepted by RA-L.
- \[2021.06\] We have released our code and pretrained models for [https://sites.google.com/view/mif-wlstm MIF-WLSTM] on the GitHub repo [https://github.com/tedhuang96/mifwlstm mifwlstm].
- \[2020.11\] One paper [https://sites.google.com/view/mif-wlstm MIF-WLSTM] is accepted by RA-L.
- \[2020.05\] One paper is accepted by ITSC 2020.
- \[2020.01\] One paper is accepted by RA-L and ICRA 2020.

== Publications
~~~
{}{img_left}{pics/icp.png}{alt text}{200}{111}
[https://www.algorithmic-robotics.org/papers/60_Interaction_aware_Conformal.pdf *Interaction-aware Conformal Prediction for Crowd Navigation*]\n\n
*Zhe Huang*, Tianchen Ji, Heling Zhang, Fatemeh Cheraghi Pouria, Katherine Driggs-Campbell, Roy Dong \n\n
WAFR 2024 \n\n
\[[https://www.algorithmic-robotics.org/papers/60_Interaction_aware_Conformal.pdf paper]\]
~~~

~~~
{}{img_left}{pics/lit.png}{alt text}{200}{82}
[https://arxiv.org/abs/2406.13787 *LIT: Large Language Model Driven Intention Tracking for Proactive Human-Robot Collaboration -- A Robot Sous-Chef Application*]\n\n
*Zhe Huang*, John Pohovey, Ananya Yammanuru, Katherine Driggs-Campbell \n\n
*Spotlight Presentation* at CVPR 2024 [https://computer-vision-in-the-wild.github.io/cvpr-2024/ Workshop on Computer Vision in the Wild] \n\n
CVPR 2024 Annual Embodied AI Workshop \n\n
\[[https://arxiv.org/abs/2406.13787 arXiv]\]
~~~

~~~
{}{img_left}{pics/nirrt*.png}{alt text}{200}{200}
[https://sites.google.com/view/nirrt-star *Neural Informed RRT\*: Learning-based Path Planning with Point Cloud State Representations under Admissible Ellipsoidal Constraints*]\n\n
*Zhe Huang*, Hongyu Chen, John Pohovey, Katherine Driggs-Campbell \n\n
ICRA 2024 \n\n
\[[https://ieeexplore.ieee.org/abstract/document/10611099 paper]\]
\[[https://arxiv.org/abs/2309.14595 arXiv]\]
\[[https://sites.google.com/view/nirrt-star project]\]
\[[https://github.com/tedhuang96/nirrt_star main code]\]
\[[https://github.com/tedhuang96/PNGNav ROS code]\]
\[[https://youtu.be/xys6XxMqFqQ presentation]\]
\[[https://youtu.be/XjZqUJ0ufGA demo]\]
~~~

~~~
{}{img_left}{pics/hit.png}{alt text}{200}{151}
[https://sites.google.com/view/hierarchicalintentiontracking *Hierarchical Intention Tracking for Robust Human-Robot Collaboration in Industrial Assembly Tasks*] \n\n
*Zhe Huang*\*, Ye-Ji Mun\*, Xiang Li†, Yiqing Xie†, Ninghan Zhong†, Weihang Liang, Junyi Geng, Tan Chen, Katherine Driggs-Campbell \n\n
ICRA 2023 \n\n
\[[https://ieeexplore.ieee.org/abstract/document/10160515 paper]\]
\[[https://arxiv.org/abs/2203.09063 arXiv]\]
\[[https://sites.google.com/view/hierarchicalintentiontracking project]\]
\[[https://youtu.be/lcSl-Jz3_mE presentation]\]
~~~

~~~
{}{img_left}{pics/crowdnav++.gif}{alt text}{200}{200}
[https://sites.google.com/view/intention-aware-crowdnav/ *Intention Aware Robot Crowd Navigation with Attention-Based Interaction Graph*] \n\n
Shuijing Liu, Peixin Chang, *Zhe Huang*, Neeloy Chakraborty, Kaiwen Hong, Weihang Liang, D. Livingston McPherson, Junyi Geng, Katherine Driggs-Campbell \n\n
ICRA 2023 \n\n
\[[https://ieeexplore.ieee.org/abstract/document/10160660 paper]\]
\[[https://arxiv.org/abs/2203.01821 arXiv]\]
\[[https://sites.google.com/view/intention-aware-crowdnav/ project]\]
\[[https://github.com/Shuijing725/CrowdNav_Prediction_AttnGraph code]\]
\[[https://youtu.be/boDDQvZ1yV0 presentation]\]
\[[https://youtu.be/d9va6QW9sYA demo]\]
~~~

~~~
{}{img_left}{pics/gst.png}{alt text}{200}{225}
[https://ieeexplore.ieee.org/abstract/document/9664278 *Learning Sparse Interaction Graphs of Partially Detected Pedestrians for Trajectory Prediction*] \n\n
*Zhe Huang*, Ruohua Li, Kazuki Shin, Katherine Driggs-Campbell \n\n
RA-L with ICRA 2022 presentation option \n\n
\[[https://ieeexplore.ieee.org/abstract/document/9664278 paper]\]
\[[https://arxiv.org/abs/2107.07056 arXiv]\]
\[[https://sites.google.com/view/gumbel-social-transformer project]\]
\[[https://github.com/tedhuang96/gst code]\]
\[[https://youtu.be/fHYg1zaMcxE presentation]\]
\[[https://youtu.be/oL2UlN53wUc demo]\]
~~~

~~~
{}{img_left}{pics/mifwlstm.gif}{alt text}{200}{117}
[https://ieeexplore.ieee.org/abstract/document/9309334 *Long-Term Pedestrian Trajectory Prediction Using Mutable Intention Filter and Warp LSTM*] \n\n
*Zhe Huang*, Aamir Hasan, Kazuki Shin, Ruohua Li, Katherine Driggs-Campbell \n\n
RA-L 2020 \n\n
\[[https://ieeexplore.ieee.org/abstract/document/9309334 paper]\]
\[[https://arxiv.org/abs/2007.00113 arXiv]\]
\[[https://github.com/tedhuang96/mifwlstm code]\]
~~~

~~~
{}{img_left}{pics/online_monitoring.png}{alt text}{200}{153}
[https://ieeexplore.ieee.org/abstract/document/9294366 *Online Monitoring for Safe Pedestrian-Vehicle Interactions*] \n\n
Peter Du, *Zhe Huang*†, Tianqi Liu†, Tianchen Ji†, Ke Xu†, Qichao Gao†,Hussein Sibai, Katherine Driggs-Campbell, Sayan Mitra\n\n
ITSC 2020 \n\n
\[[https://ieeexplore.ieee.org/abstract/document/9294366 paper]\]
\[[https://arxiv.org/abs/1910.05599 arXiv]\]
~~~

~~~
{}{img_left}{pics/softrobot_antenna.png}{alt text}{200}{208}
[https://ieeexplore.ieee.org/abstract/document/8972415 *3D Electromagnetic Reconfiguration Enabled by Soft Continuum Robots*] \n\n
Lucia T. Gan, Laura H. Blumenschein, *Zhe Huang*, Allison M. Okamura, Elliot W. Hawkes, Jonathan A. Fan\n\n
RA-L 2020 \n\n
\[[https://ieeexplore.ieee.org/abstract/document/8972415 paper]\]
~~~

~~~
{}{img_left}{pics/drillbot.png}{alt text}{200}{152}
[https://onepetro.org/SPEDC/proceedings-abstract/20DC/2-20DC/447222 *A Voice Interface for Drilling Systems*] \n\n
Crispin Chatar, *Zhe Huang*, Peter Hadrovic\n\n
IADC/SPE International Drilling Conference and Exhibition 2020 \n\n
\[[https://onepetro.org/SPEDC/proceedings-abstract/20DC/2-20DC/447222 paper]\]
~~~

~~~
{}{img_left}{pics/fly-by-feel.png}{alt text}{200}{153}
[https://www.dpi-proceedings.com/index.php/shm2019/article/view/32298 *High Accuracy Flight State Identification of a Self-Sensing Wing via Machine Learning Approaches*] \n\n
*Zhe Huang*, Hongyi Zhao, Cheng Liu, Xi Chen, Fotis Kopsaftopoulos, Fu-Kuo Chang\n\n
Structural Health Monitoring 2019 \n\n
\[[https://www.dpi-proceedings.com/index.php/shm2019/article/view/32298 paper]\]
~~~
